name: MLOps CI Pipeline

# ============================================================
# MLOps CI/CD Pipeline for Clinical Trial Dropout Prediction
# ============================================================
# 
# This pipeline implements GUARDED AUTOMATION:
# - Runs tests on every PR and push to main
# - Validates data + model behavior
# - Trains model with MLflow tracking
# - Enforces quality gates before promotion
# - NEVER deploys a worse model
#
# Philosophy: "Automation over trust"
# ============================================================

on:
  pull_request:
    branches: [ main ]
  push:
    branches: [ main ]
  schedule:
    # Run daily at midnight to check for drift
    - cron: '0 0 * * *'
  workflow_dispatch:  # Allow manual triggering


env:
  PYTHON_VERSION: '3.10'
  MLFLOW_TRACKING_URI: 'sqlite:///mlflow.db'

jobs:
  # ============================================================
  # Stage 1: Data Validation
  # ============================================================
  data-validation:
    name: ðŸ“Š Data Quality Checks
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Setup DVC
      run: |
        pip install dvc
        # Configure DVC remote (if needed)
        # dvc remote modify origin --local access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
    
    - name: Pull data via DVC
      continue-on-error: true  # Don't fail if DVC pull fails (data might be local)
      run: |
        dvc pull || echo "DVC pull skipped - using local data"
    
    - name: Run data validation tests
      run: |
        pytest tests/test_data.py -v --tb=short

  # ============================================================
  # Stage 2: Feature Engineering Validation
  # ============================================================
  feature-validation:
    name: ðŸ”§ Feature Engineering Checks
    runs-on: ubuntu-latest
    needs: data-validation
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Pull data via DVC
      continue-on-error: true
      run: |
        pip install dvc
        dvc pull || echo "DVC pull skipped - using local data"
    
    - name: Run feature validation tests
      run: |
        pytest tests/test_features.py -v --tb=short

  # ============================================================
  # Stage 3: Model Training
  # ============================================================
  model-training:
    name: ðŸŽ¯ Model Training
    runs-on: ubuntu-latest
    needs: feature-validation
    outputs:
      retrain: ${{ steps.retrain_check.outputs.retrain }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Pull data via DVC
      continue-on-error: true
      run: |
        pip install dvc
        dvc pull || echo "DVC pull skipped - using local data"
    
    - name: Generate synthetic data (fallback)
      run: |
        mkdir -p data/raw data/processed monitoring
        if [ ! -f "data/raw/clinical_trials_realistic_v5.csv" ]; then
          python data/synthetic_data_final.py
        fi

    # 1. Simulate Production Data (for Drift Check)
    - name: Simulate live predictions (if missing)
      run: |
        if [ ! -f "monitoring/live_predictions.jsonl" ]; then
          echo "âš ï¸ Generating dummy predictions for drift check..."
          # Create a small valid jsonl file
          echo '{"input": {"age": 60, "visits": 5}, "output": {"dropout": 1}}' > monitoring/live_predictions.jsonl
        fi

    # 2. Run Drift Detection
    - name: Run drift detection
      id: drift_detect
      run: |
        # Ensure reference data exists
        python monitoring/build_reference.py
        # Run drift analysis (generates drift_summary.json)
        python monitoring/run_drift.py

    # 3. Decision Brain
    - name: Check retraining condition
      id: retrain_check
      run: |
        # Decision brain
        OUTPUT=$(python monitoring/should_retrain.py)
        echo "$OUTPUT"
        
        # Parse output for flag
        if echo "$OUTPUT" | grep -q "RETRAIN_REQUIRED=true"; then
          echo "retrain=true" >> $GITHUB_OUTPUT
          echo "::notice::ðŸ”´ Retraining TRIGGERED"
        else
          echo "retrain=false" >> $GITHUB_OUTPUT
          echo "::notice::ðŸŸ¢ Retraining NOT required"
        fi

    # 4. Conditional Training
    - name: Train model (Conditional)
      if: steps.retrain_check.outputs.retrain == 'true' || github.event_name == 'push'
      run: |
        echo "ðŸš€ Starting training pipeline..."
        python pipelines/local_pipeline.py

    - name: Upload MLflow artifacts
      if: steps.retrain_check.outputs.retrain == 'true' || github.event_name == 'push'
      uses: actions/upload-artifact@v4
      with:
        name: mlflow-artifacts
        path: |
          mlflow.db
          mlruns/
          models/
          data/processed/
          monitoring/drift_summary.json
        retention-days: 7

  # ============================================================
  # Stage 4: Model Quality Gate
  # ============================================================
  model-validation:
    name: ðŸ”’ Quality Gate Check
    runs-on: ubuntu-latest
    needs: model-training
    # Only run if training actually happened (or artifacts were uploaded)
    if: needs.model-training.outputs.retrain == 'true' || github.event_name == 'push'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Download MLflow artifacts
      uses: actions/download-artifact@v4
      with:
        name: mlflow-artifacts
    
    - name: Validate model metrics
      run: |
        python scripts/validate_metrics.py
        
    - name: Run model tests
      continue-on-error: true
      run: |
        pytest tests/test_model.py -v --tb=short

  # ============================================================
  # Stage 5: Safe Promotion (Day 16 Feature)
  # ============================================================
  model-promotion:
    name: ðŸš€ Compare & Promote
    runs-on: ubuntu-latest
    needs: model-validation
    if: success()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: pip install mlflow
      
    - name: Download artifacts
      uses: actions/download-artifact@v4
      with:
        name: mlflow-artifacts
        
    - name: Compare with Production
      run: |
        python scripts/compare_with_production.py

  # ============================================================
  # Stage 5: Integration Tests (API)
  # ============================================================
  integration-tests:
    name: ðŸ§ª Integration Tests
    runs-on: ubuntu-latest
    needs: model-validation
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Download MLflow artifacts
      uses: actions/download-artifact@v4
      with:
        name: mlflow-artifacts
    
    - name: Test API endpoints
      run: |
        # Start API server in background
        uvicorn api.main:app --host 0.0.0.0 --port 8000 &
        sleep 5
        
        # Health check
        curl -f http://localhost:8000/health || exit 1
        
        # Prediction test (all required fields)
        curl -f -X POST http://localhost:8000/predict \
          -H "Content-Type: application/json" \
          -d '{
            "patient_id": "TEST-001",
            "age": 55,
            "gender": "Male",
            "treatment_group": "Active",
            "trial_phase": "Phase II",
            "days_in_trial": 90,
            "visits_completed": 3,
            "last_visit_day": 80,
            "adverse_events": 2
          }' \
          || exit 1
        
        echo "âœ… API integration tests passed"

  # ============================================================
  # Stage 6: Build Docker Image (on main only)
  # ============================================================
  docker-build:
    name: ðŸ³ Docker Build
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download MLflow artifacts
      uses: actions/download-artifact@v4
      with:
        name: mlflow-artifacts
    
    - name: Prepare Docker build context
      run: |
        echo "=== Preparing Docker build context ==="
        # Ensure directories exist
        mkdir -p models data/processed monitoring
        
        # List what we have
        echo "=== Directory structure ==="
        ls -la
        ls -la models/ || echo "models/ empty"
        ls -la data/processed/ || echo "data/processed/ empty"
        
        # Create placeholder if models is empty (for Docker build to succeed)
        if [ ! -f models/*.pkl ] 2>/dev/null; then
          echo "No model files found - Docker will need model files mounted at runtime"
        fi
    
    - name: Build Docker image
      run: |
        docker build -t clinical-trial-mlops:${{ github.sha }} .
        docker build -t clinical-trial-mlops:latest .
    
    - name: Test Docker container
      run: |
        # Run container
        docker run -d -p 8000:8000 --name test-container clinical-trial-mlops:latest
        
        # Wait for container to start (increased time)
        echo "Waiting for container to start..."
        sleep 30
        
        # Show container logs for debugging
        echo "=== Container logs ==="
        docker logs test-container || true
        
        # Health check with retries
        echo "=== Health check ==="
        for i in 1 2 3 4 5; do
          if curl -f http://localhost:8000/health; then
            echo "âœ… Health check passed!"
            break
          fi
          echo "Attempt $i failed, waiting..."
          sleep 5
        done
        
        # Final check
        curl -f http://localhost:8000/health || (docker logs test-container && exit 1)
        
        # Cleanup
        docker stop test-container
        docker rm test-container
        
        echo "âœ… Docker build and test passed"
    
    # Uncomment to push to container registry
    # - name: Push to Container Registry
    #   run: |
    #     docker tag clinical-trial-mlops:latest ${{ secrets.REGISTRY }}/clinical-trial-mlops:latest
    #     docker push ${{ secrets.REGISTRY }}/clinical-trial-mlops:latest

  # ============================================================
  # Summary Job
  # ============================================================
  pipeline-summary:
    name: ðŸ“‹ Pipeline Summary
    runs-on: ubuntu-latest
    needs: [data-validation, feature-validation, model-training, model-validation, integration-tests]
    if: always()
    
    steps:
    - name: Pipeline Status
      run: |
        echo "============================================================"
        echo "ðŸš€ MLOps CI Pipeline Complete"
        echo "============================================================"
        echo ""
        echo "Data Validation:     ${{ needs.data-validation.result }}"
        echo "Feature Validation:  ${{ needs.feature-validation.result }}"
        echo "Model Training:      ${{ needs.model-training.result }}"
        echo "Model Validation:    ${{ needs.model-validation.result }}"
        echo "Integration Tests:   ${{ needs.integration-tests.result }}"
        echo ""
        echo "============================================================"
